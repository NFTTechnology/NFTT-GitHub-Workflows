name: Reusable PR Review v2.2 (Token Usage & Cost Tracking)

on:
  workflow_call:
    inputs:
      pr_number:
        description: 'PRç•ªå·'
        required: true
        type: string
      repository:
        description: 'ãƒªãƒã‚¸ãƒˆãƒªå (owner/repo)'
        required: true
        type: string
      review_type:
        description: 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¿ã‚¤ãƒ— (quick/balanced/detailed)'
        required: false
        type: string
        default: 'balanced'
      max_diff_lines:
        description: 'å·®åˆ†ã®æœ€å¤§è¡Œæ•°'
        required: false
        type: number
        default: 10000
      models:
        description: 'ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆJSONï¼‰'
        required: false
        type: string
        default: '{"claude": "claude-3-5-sonnet-20241022", "openai": "gpt-4o-mini"}'
      enable_code_suggestions:
        description: 'ã‚³ãƒ¼ãƒ‰ææ¡ˆã‚’å«ã‚ã‚‹ã‹'
        required: false
        type: boolean
        default: true

jobs:
  enhanced-multi-role-review:
    runs-on: ubuntu-latest
    steps:
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install anthropic openai PyGithub requests tiktoken

      - name: Get PR context with analysis
        id: pr-context
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ğŸ“¥ Fetching PR #${{ inputs.pr_number }} from ${{ inputs.repository }}"
          
          # PRæƒ…å ±ã‚’å–å¾—
          gh pr view ${{ inputs.pr_number }} \
            --repo ${{ inputs.repository }} \
            --json number,title,body,author,createdAt,additions,deletions,files,labels,baseRefName,headRefName \
            > pr_data.json
          
          # å·®åˆ†ã‚’å–å¾—
          gh pr diff ${{ inputs.pr_number }} \
            --repo ${{ inputs.repository }} \
            | head -n ${{ inputs.max_diff_lines }} > pr_diff.txt || true
          
          # å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
          jq -r '.files[].path' pr_data.json > changed_files.txt || true
          
          # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ†æ
          echo "ğŸ“Š File type analysis:"
          SOURCE_COUNT=$(grep -E '\.(js|ts|py|java|go|rb|php|cs|cpp|c)$' changed_files.txt | wc -l || echo 0)
          CONFIG_COUNT=$(grep -E '\.(yml|yaml|json|xml|ini)$' changed_files.txt | wc -l || echo 0)
          DOC_COUNT=$(grep -E '\.(md|txt|rst)$' changed_files.txt | wc -l || echo 0)
          
          echo "- Source files: $SOURCE_COUNT"
          echo "- Config files: $CONFIG_COUNT"
          echo "- Doc files: $DOC_COUNT"

      - name: Run enhanced multi-role AI review
        id: ai-review
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          MODELS_CONFIG: ${{ inputs.models }}
          REVIEW_TYPE: ${{ inputs.review_type }}
          ENABLE_SUGGESTIONS: ${{ inputs.enable_code_suggestions }}
        run: |
          cat > enhanced_multi_role_review.py << 'PYTHON_SCRIPT'
          import os
          import json
          import re
          import anthropic
          import openai
          import tiktoken
          from datetime import datetime
          
          # è¨­å®š
          models = json.loads(os.getenv('MODELS_CONFIG'))
          review_type = os.getenv('REVIEW_TYPE', 'balanced')
          enable_suggestions = os.getenv('ENABLE_SUGGESTIONS', 'true').lower() == 'true'
          
          # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
          with open('pr_data.json', 'r') as f:
              pr_data = json.load(f)
          
          try:
              with open('pr_diff.txt', 'r') as f:
                  diff_content = f.read()
          except:
              diff_content = "å·®åˆ†ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"
          
          try:
              with open('changed_files.txt', 'r') as f:
                  changed_files = [line.strip() for line in f if line.strip()]
          except:
              changed_files = []
          
          # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©ï¼ˆå¼·åŒ–ç‰ˆï¼‰
          security_patterns = {
              'password_plain': {
                  'pattern': r'(?i)(password|passwd|pwd)\s*[:=]\s*["\']?[^"\'\s\{\}]+["\']?(?!\s*\.|->)',
                  'severity': 'critical',
                  'message': 'ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®å¹³æ–‡ä¿å­˜'
              },
              'sql_injection': {
                  'pattern': r'(?i)(SELECT|INSERT|UPDATE|DELETE|DROP).*["\']?\s*\+\s*[^"\']+["\']?|f["\'].*{.*}.*(?:WHERE|VALUES)',
                  'severity': 'critical',
                  'message': 'SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã®å¯èƒ½æ€§'
              },
              'hardcoded_secret': {
                  'pattern': r'(?i)(api[_-]?key|secret|token|password|passwd)\s*[:=]\s*["\'][^"\']{10,}["\']',
                  'severity': 'high',
                  'message': 'ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸèªè¨¼æƒ…å ±'
              },
              'unsafe_eval': {
                  'pattern': r'(?i)(eval|exec)\s*\([^)]*\)|new\s+Function\s*\(',
                  'severity': 'high',
                  'message': 'å®‰å…¨ã§ãªã„å‹•çš„ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ'
              },
              'weak_crypto': {
                  'pattern': r'(?i)(MD5|SHA1|DES|RC4)|Math\.random\(\)',
                  'severity': 'medium',
                  'message': 'å¼±ã„æš—å·åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ '
              },
              'sensitive_log': {
                  'pattern': r'(?i)console\.(log|error|warn).*(?:password|token|secret|key|card)',
                  'severity': 'medium',
                  'message': 'æ©Ÿå¯†æƒ…å ±ã®ãƒ­ã‚°å‡ºåŠ›'
              },
              'missing_auth': {
                  'pattern': r'@(app\.)?route\s*\([^)]+\)(?!\s*\n\s*@(auth|login)_required)',
                  'severity': 'medium',
                  'message': 'èªè¨¼ãƒã‚§ãƒƒã‚¯ãªã—'
              }
          }
          
          # PRæƒ…å ±
          pr_number = pr_data.get('number', 'N/A')
          pr_title = pr_data.get('title', 'No title')
          pr_body = pr_data.get('body', 'No description')
          pr_author = pr_data.get('author', {}).get('login', 'Unknown')
          additions = pr_data.get('additions', 0)
          deletions = pr_data.get('deletions', 0)
          base_branch = pr_data.get('baseRefName', 'unknown')
          head_branch = pr_data.get('headRefName', 'unknown')
          
          # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ†æ
          file_priorities = {
              '.js': 'high', '.ts': 'high', '.jsx': 'high', '.tsx': 'high',
              '.py': 'high', '.java': 'high', '.go': 'high', '.rb': 'high',
              '.php': 'high', '.cs': 'high', '.cpp': 'high', '.c': 'high',
              '.yml': 'medium', '.yaml': 'medium', '.json': 'medium',
              '.xml': 'medium', '.ini': 'medium', '.env': 'high',
              '.md': 'low', '.txt': 'low', '.rst': 'low'
          }
          
          source_files = []
          config_files = []
          other_files = []
          
          for file in pr_data.get('files', []):
              path = file.get('path', '')
              ext = os.path.splitext(path)[1]
              priority = file_priorities.get(ext, 'low')
              
              file_info = {
                  'path': path,
                  'additions': file.get('additions', 0),
                  'deletions': file.get('deletions', 0),
                  'priority': priority
              }
              
              if priority == 'high':
                  source_files.append(file_info)
              elif priority == 'medium':
                  config_files.append(file_info)
              else:
                  other_files.append(file_info)
          
          # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒã‚§ãƒƒã‚¯
          security_issues = []
          for pattern_name, pattern_info in security_patterns.items():
              matches = re.findall(pattern_info['pattern'], diff_content, re.IGNORECASE | re.MULTILINE)
              if matches:
                  security_issues.append({
                      'type': pattern_name,
                      'severity': pattern_info['severity'],
                      'message': pattern_info['message'],
                      'count': len(matches),
                      'samples': matches[:3]
                  })
          
          # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œã‚’æ·±åˆ»åº¦ã§ã‚½ãƒ¼ãƒˆ
          security_issues.sort(key=lambda x: {'critical': 0, 'high': 1, 'medium': 2}.get(x['severity'], 3))
          
          # ãƒ¬ãƒ“ãƒ¥ãƒ¼è¨­å®š
          review_depth = {
              'quick': {'roles': 2, 'max_items': 3, 'tokens': 400},
              'balanced': {'roles': 4, 'max_items': 4, 'tokens': 600},
              'detailed': {'roles': 4, 'max_items': 6, 'tokens': 1000}
          }[review_type]
          
          # ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ä¸­å¿ƒã®å·®åˆ†æŠ½å‡º
          source_diff = ""
          if source_files:
              for file in source_files[:10]:  # æœ€å¤§10ãƒ•ã‚¡ã‚¤ãƒ«
                  file_pattern = rf"diff --git.*{re.escape(file['path'])}.*?(?=diff --git|$)"
                  file_diff = re.search(file_pattern, diff_content, re.DOTALL)
                  if file_diff:
                      source_diff += file_diff.group(0) + "\n\n"
          
          # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ­ãƒ¼ãƒ«å®šç¾©ï¼ˆå¼·åŒ–ç‰ˆï¼‰
          all_roles = [
              {
                  'name': 'Security Engineer',
                  'emoji': 'ğŸ”’',
                  'model': 'claude',
                  'focus': 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã€èªè¨¼èªå¯ã€ãƒ‡ãƒ¼ã‚¿ä¿è­·ã€æš—å·åŒ–ã€ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ”»æ’ƒ',
                  'priority': 'critical',
                  'patterns': ['password_plain', 'sql_injection', 'hardcoded_secret', 'unsafe_eval']
              },
              {
                  'name': 'QA Engineer',
                  'emoji': 'ğŸ§ª',
                  'model': 'openai',
                  'focus': 'ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€å¢ƒç•Œå€¤ã€ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã€å›å¸°ãƒªã‚¹ã‚¯ã€ãƒã‚°',
                  'priority': 'high',
                  'patterns': ['missing_auth', 'sensitive_log']
              },
              {
                  'name': 'Senior Architect',
                  'emoji': 'ğŸ—ï¸',
                  'model': 'claude',
                  'focus': 'ã‚³ãƒ¼ãƒ‰å“è³ªã€è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ä¿å®ˆæ€§ã€æŠ€è¡“çš„è² å‚µ',
                  'priority': 'medium',
                  'patterns': ['weak_crypto']
              },
              {
                  'name': 'Product Manager',
                  'emoji': 'ğŸ“±',
                  'model': 'openai',
                  'focus': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼å½±éŸ¿ã€è¦ä»¶é©åˆæ€§ã€ä½¿ã„ã‚„ã™ã•ã€ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã€ç§»è¡Œè¨ˆç”»',
                  'priority': 'low',
                  'patterns': []
              }
          ]
          
          # ä½¿ç”¨ã™ã‚‹ãƒ­ãƒ¼ãƒ«ã‚’é¸æŠ
          roles = all_roles[:review_depth['roles']]
          
          # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œã®æƒ…å ±ã‚’æ•´ç†
          security_summary = ""
          if security_issues:
              security_summary = "\\n## ğŸš¨ è‡ªå‹•æ¤œå‡ºã•ã‚ŒãŸã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œ\\n"
              for issue in security_issues[:5]:  # æœ€å¤§5ä»¶
                  security_summary += f"- **{issue['message']}** ({issue['severity']}): {issue['count']}ä»¶æ¤œå‡º\\n"
          
          # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
          context = f"""
          PR #{pr_number}: {pr_title}
          Author: @{pr_author}
          Branch: {head_branch} â†’ {base_branch}
          Changes: +{additions} -{deletions} in {len(changed_files)} files
          
          {security_summary}
          
          Description:
          {pr_body[:1500]}
          
          Changed files:
          {chr(10).join(f'- {f["path"]} (+{f["additions"]} -{f["deletions"]})' for f in source_files[:10])}
          {'... and ' + str(len(source_files) - 10) + ' more source files' if len(source_files) > 10 else ''}
          
          Source code diff:
          {source_diff[:8000]}
          """
          
          # ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã®åˆæœŸåŒ–
          try:
              # GPT-4ç”¨ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
              encoding = tiktoken.encoding_for_model('gpt-4')
          except:
              # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
              encoding = tiktoken.get_encoding('cl100k_base')
          
          # å„ãƒ­ãƒ¼ãƒ«ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼
          reviews = []
          token_usage = {'claude': {'input': 0, 'output': 0}, 'openai': {'input': 0, 'output': 0}}
          
          for role in roles:
              # ãƒ­ãƒ¼ãƒ«å°‚ç”¨ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œ
              role_issues = [issue for issue in security_issues if issue['type'] in role['patterns']]
              
              prompt = f"""
              ã‚ãªãŸã¯{role['name']}ã¨ã—ã¦ã€ä»¥ä¸‹ã®PRã‚’å³å¯†ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ã€‚
              è¦³ç‚¹: {role['focus']}
              
              {context}
              
              {"ä»¥ä¸‹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ï¼š" if role_issues else ""}
              {chr(10).join(f"- {issue['message']}: {issue['count']}ä»¶" for issue in role_issues)}
              
              {role['priority']}å„ªå…ˆåº¦ã®å•é¡Œã‚’æœ€å¤§{review_depth['max_items']}å€‹æŒ™ã’ã¦ãã ã•ã„ã€‚
              å¿…ãšä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
              1. å…·ä½“çš„ãªè¡Œç•ªå·ã¾ãŸã¯ã‚³ãƒ¼ãƒ‰å¼•ç”¨
              2. å•é¡Œã®å½±éŸ¿ã¨æ·±åˆ»åº¦
              {'3. ä¿®æ­£ä¾‹ã®ã‚³ãƒ¼ãƒ‰' if enable_suggestions else '3. ä¿®æ­£æ–¹é‡'}
              
              å½¢å¼:
              {'ğŸš¨' if role['priority'] == 'critical' else 'âš ï¸' if role['priority'] == 'high' else 'â„¹ï¸'} [å•é¡Œã®ã‚¿ã‚¤ãƒˆãƒ«]
              - è©²å½“ç®‡æ‰€: `ãƒ•ã‚¡ã‚¤ãƒ«å:è¡Œç•ªå·` ã¾ãŸã¯å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰
              - å½±éŸ¿: [å…·ä½“çš„ãªå½±éŸ¿]
              {'- ä¿®æ­£ä¾‹:' + chr(10) + '```language' + chr(10) + '// ä¿®æ­£ã‚³ãƒ¼ãƒ‰' + chr(10) + '```' if enable_suggestions else '- ä¿®æ­£æ–¹é‡: [æ–¹é‡]'}
              """
              
              try:
                  if role['model'] == 'claude':
                      client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
                      response = client.messages.create(
                          model=models['claude'],
                          max_tokens=review_depth['tokens'],
                          temperature=0.3,
                          messages=[{"role": "user", "content": prompt}]
                      )
                      review_text = response.content[0].text
                      # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²
                      # Claude APIã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’tiktokenã§æ¨å®š
                      # Claudeã¨GPTã¯ã»ã¼åŒã˜ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ä½¿ç”¨
                      input_tokens = len(encoding.encode(prompt))
                      output_tokens = len(encoding.encode(review_text))
                      token_usage['claude']['input'] += input_tokens
                      token_usage['claude']['output'] += output_tokens
                      print(f"Claude tokens (tiktoken) - input: {input_tokens}, output: {output_tokens}")
                  else:
                      client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
                      response = client.chat.completions.create(
                          model=models['openai'],
                          max_tokens=review_depth['tokens'],
                          temperature=0.3,
                          messages=[{"role": "user", "content": prompt}]
                      )
                      review_text = response.choices[0].message.content
                      # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²
                      # OpenAI APIã¯ä½¿ç”¨é‡ã‚’è¿”ã™
                      if response.usage:
                          token_usage['openai']['input'] += response.usage.prompt_tokens
                          token_usage['openai']['output'] += response.usage.completion_tokens
                          print(f"OpenAI tokens - input: {response.usage.prompt_tokens}, output: {response.usage.completion_tokens}")
                  
                  reviews.append({
                      'role': role['name'],
                      'emoji': role['emoji'],
                      'priority': role['priority'],
                      'content': review_text.strip()
                  })
              except Exception as e:
                  print(f"Error in {role['name']} review: {e}")
                  reviews.append({
                      'role': role['name'],
                      'emoji': role['emoji'],
                      'priority': role['priority'],
                      'content': f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}"
                  })
          
          # ç·åˆè©•ä¾¡ã®ä½œæˆ
          summary_prompt = f"""
          ä»¥ä¸‹ã®{len(reviews)}äººã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‹ã‚‰ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ã€è‡ªå‹•æ¤œå‡ºã•ã‚ŒãŸ{len(security_issues)}ä»¶ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œã‚’çµ±åˆã—ã¦ã€æœ€çµ‚è©•ä¾¡ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
          
          è‡ªå‹•æ¤œå‡º:
          {chr(10).join(f"- {issue['message']} ({issue['severity']}): {issue['count']}ä»¶" for issue in security_issues[:5])}
          
          ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…å®¹:
          {chr(10).join(f"{r['emoji']} {r['role']}: {r['content'][:300]}..." for r in reviews)}
          
          ä»¥ä¸‹ã®å½¢å¼ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ï¼š
          
          ## åˆ¤å®š
          [âœ… æ‰¿èªå¯èƒ½ / âš ï¸ æ¡ä»¶ä»˜ãæ‰¿èª / ğŸš« è¦ä¿®æ­£]
          
          ## å¿…é ˆå¯¾å¿œ (ãƒ–ãƒ­ãƒƒã‚«ãƒ¼)
          æœ€é‡è¦é …ç›®ã®ã¿ã€æœ€å¤§3å€‹ï¼ˆè‡ªå‹•æ¤œå‡ºã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’çµ±åˆï¼‰
          
          ## æ¨å¥¨å¯¾å¿œ
          æ”¹å–„ææ¡ˆã€æœ€å¤§3å€‹
          
          ## è‰¯ã„ç‚¹
          1-2å€‹ã€ç°¡æ½”ã«
          """
          
          # ç·åˆè©•ä¾¡ç”Ÿæˆ
          try:
              client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
              summary_response = client.messages.create(
                  model=models['claude'],
                  max_tokens=800,
                  temperature=0.2,
                  messages=[{"role": "user", "content": summary_prompt}]
              )
              summary = summary_response.content[0].text.strip()
              # ç·åˆè©•ä¾¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚‚è¨˜éŒ²
              # ç·åˆè©•ä¾¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚‚tiktokenã§è¨ˆæ¸¬
              summary_input_tokens = len(encoding.encode(summary_prompt))
              summary_output_tokens = len(encoding.encode(summary))
              token_usage['claude']['input'] += summary_input_tokens
              token_usage['claude']['output'] += summary_output_tokens
              print(f"Summary tokens (tiktoken) - input: {summary_input_tokens}, output: {summary_output_tokens}")
          except:
              summary = "ç·åˆè©•ä¾¡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
          
          # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
          report = f"""# ğŸ¤– AI Multi-Role Code Review v2.2
          
          **PR:** #{pr_number} {pr_title}
          **Review Type:** {review_type.title()} ({len(roles)} roles)
          **Security Issues Detected:** {len(security_issues)}
          **Timestamp:** {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}
          
          {summary}
          
          ---
          
          ## ğŸ” è‡ªå‹•ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³çµæœ
          
          """
          
          if security_issues:
              for issue in security_issues[:5]:
                  report += f"### {issue['message']} ({issue['severity'].upper()})\n"
                  report += f"- æ¤œå‡ºæ•°: {issue['count']}ä»¶\n"
                  if issue['samples'] and enable_suggestions:
                      report += f"- ã‚µãƒ³ãƒ—ãƒ«: `{issue['samples'][0][:50]}...`\n"
                  report += "\n"
          else:
              report += "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è‡ªå‹•æ¤œå‡ºã§ã¯å•é¡Œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n"
          
          report += "---\n\n## ğŸ‘¥ ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼\n\n"
          
          # å„ãƒ­ãƒ¼ãƒ«ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¿½åŠ 
          for review in reviews:
              if review['content'] and "ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼" not in review['content']:
                  report += f"### {review['emoji']} {review['role']}\n\n"
                  report += review['content'] + "\n\n"
          
          # ã‚³ã‚¹ãƒˆè¨ˆç®—
          print(f"\n=== Token Usage Summary ===")
          print(f"Claude: input={token_usage['claude']['input']}, output={token_usage['claude']['output']}")
          print(f"OpenAI: input={token_usage['openai']['input']}, output={token_usage['openai']['output']}")
          print("========================\n")
          
          pricing = {
              'claude': {'input': 0.003, 'output': 0.015},  # per 1K tokens
              'openai': {'input': 0.00015, 'output': 0.0006}  # GPT-4o-mini pricing
          }
          
          total_cost = 0
          token_report = "### ğŸ’° Token Usage & Cost\n\n"
          token_report += "| Model | Input Tokens | Output Tokens | Cost (USD) |\n"
          token_report += "|-------|-------------|---------------|------------|\n"
          
          # Claudeä½¿ç”¨é‡ï¼ˆå¸¸ã«è¡¨ç¤ºï¼‰
          claude_input = max(token_usage['claude']['input'], 1)  # æœ€å°1ãƒˆãƒ¼ã‚¯ãƒ³
          claude_output = max(token_usage['claude']['output'], 1)
          claude_cost = (claude_input / 1000 * pricing['claude']['input'] + 
                        claude_output / 1000 * pricing['claude']['output'])
          total_cost += claude_cost
          token_report += f"| {models['claude']} | {claude_input:,} | {claude_output:,} | ${claude_cost:.4f} |\n"
          
          # OpenAIä½¿ç”¨é‡ï¼ˆå¸¸ã«è¡¨ç¤ºï¼‰
          openai_input = max(token_usage['openai']['input'], 1)  # æœ€å°1ãƒˆãƒ¼ã‚¯ãƒ³
          openai_output = max(token_usage['openai']['output'], 1)
          openai_cost = (openai_input / 1000 * pricing['openai']['input'] + 
                        openai_output / 1000 * pricing['openai']['output'])
          total_cost += openai_cost
          token_report += f"| {models['openai']} | {openai_input:,} | {openai_output:,} | ${openai_cost:.4f} |\n"
          
          # åˆè¨ˆ
          total_input = claude_input + openai_input
          total_output = claude_output + openai_output
          token_report += f"| **Total** | **{total_input:,}** | **{total_output:,}** | **${total_cost:.4f}** |\n\n"
          
          report += f"""---
          
          {token_report}
          
          <details>
          <summary>ğŸ“Š Review Statistics</summary>
          
          - Files analyzed: {len(source_files)} source, {len(config_files)} config, {len(other_files)} other
          - Security patterns checked: {len(security_patterns)}
          - Issues found: {len(security_issues)}
          - Lines of diff: {len(diff_content.splitlines())}
          - Review depth: {review_type}
          - Total tokens used: {total_input + total_output:,}
          
          </details>
          
          <sub>ğŸ¤– Enhanced multi-role review v2.2 with cost tracking by [NFTT-GitHub-Workflows](https://github.com/NFTTechnology/NFTT-GitHub-Workflows) | ğŸ’¡ [Feedback](https://github.com/NFTTechnology/NFTT-GitHub-Workflows/issues)</sub>
          """
          
          # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
          with open('review_report.md', 'w', encoding='utf-8') as f:
              f.write(report)
          
          # åˆ¤å®šçµæœã‚’å‡ºåŠ›ï¼ˆGitHub Actionsç”¨ï¼‰
          if 'âœ… æ‰¿èªå¯èƒ½' in summary:
              print("::set-output name=verdict::approved")
          elif 'âš ï¸ æ¡ä»¶ä»˜ãæ‰¿èª' in summary:
              print("::set-output name=verdict::conditional")
          else:
              print("::set-output name=verdict::changes_requested")
          
          print(f"Enhanced multi-role review completed. Security issues: {len(security_issues)}")
          PYTHON_SCRIPT
          
          python enhanced_multi_role_review.py

      - name: Post review comment
        if: success()
        env:
          GH_TOKEN: ${{ secrets.GH_PAT || secrets.GITHUB_TOKEN }}
        run: |
          if [[ -f "review_report.md" ]]; then
            REPORT=$(cat review_report.md)
            
            # PRã«ã‚³ãƒ¡ãƒ³ãƒˆã‚’æŠ•ç¨¿
            gh pr comment ${{ inputs.pr_number }} \
              --repo ${{ inputs.repository }} \
              --body "$REPORT"
            
            echo "âœ… Enhanced multi-role review posted successfully"
          else
            echo "âŒ Review report not found"
            exit 1
          fi

      - name: Add review labels and reactions
        if: success()
        env:
          GH_TOKEN: ${{ secrets.GH_PAT || secrets.GITHUB_TOKEN }}
        run: |
          PR_NUMBER="${{ inputs.pr_number }}"
          REPO="${{ inputs.repository }}"
          
          # ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¸ˆã¿ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
          gh pr edit $PR_NUMBER --repo $REPO --add-label "ai-reviewed" || true
          
          # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡ŒãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
          if grep -q "Security Issues Detected: [1-9]" review_report.md; then
            gh pr edit $PR_NUMBER --repo $REPO --add-label "security-review-needed" || true
          fi
          
          # åˆ¤å®šã«åŸºã¥ã„ã¦ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
          VERDICT="${{ steps.ai-review.outputs.verdict }}"
          if [[ "$VERDICT" == "approved" ]]; then
            gh pr edit $PR_NUMBER --repo $REPO --add-label "ready-to-merge" || true
          elif [[ "$VERDICT" == "changes_requested" ]]; then
            gh pr edit $PR_NUMBER --repo $REPO --add-label "needs-work" || true
          fi