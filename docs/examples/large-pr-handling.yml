# å¤§è¦æ¨¡PRå¯¾å¿œã®å®Ÿè£…ä¾‹
# å¤§ããªå·®åˆ†ã‚’åŠ¹ç‡çš„ã«å‡¦ç†ã™ã‚‹ãŸã‚ã®è¨­å®š

name: Large PR Handler

on:
  pull_request:
    types: [opened, synchronize]

jobs:
  # PRã‚µã‚¤ã‚ºåˆ†æ
  analyze-pr-size:
    runs-on: ubuntu-latest
    outputs:
      size_category: ${{ steps.categorize.outputs.category }}
      file_count: ${{ steps.analyze.outputs.file_count }}
      should_split: ${{ steps.analyze.outputs.should_split }}
      chunks: ${{ steps.analyze.outputs.chunks }}
    steps:
      - name: PRæƒ…å ±å–å¾—
        id: analyze
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          # PRçµ±è¨ˆæƒ…å ±å–å¾—
          pr_data=$(gh pr view ${{ github.event.pull_request.number }} \
            --repo ${{ github.repository }} \
            --json additions,deletions,files)
          
          additions=$(echo "$pr_data" | jq -r '.additions')
          deletions=$(echo "$pr_data" | jq -r '.deletions')
          file_count=$(echo "$pr_data" | jq -r '.files | length')
          total_changes=$((additions + deletions))
          
          echo "file_count=$file_count" >> $GITHUB_OUTPUT
          echo "total_changes=$total_changes" >> $GITHUB_OUTPUT
          
          # åˆ†å‰²ãŒå¿…è¦ã‹ã©ã†ã‹åˆ¤å®š
          if [ $total_changes -gt 5000 ] || [ $file_count -gt 50 ]; then
            echo "should_split=true" >> $GITHUB_OUTPUT
            
            # ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’è¨ˆç®—ï¼ˆæœ€å¤§10ãƒãƒ£ãƒ³ã‚¯ï¼‰
            chunk_size=20  # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãƒ™ãƒ¼ã‚¹
            chunks=$((($file_count + $chunk_size - 1) / $chunk_size))
            chunks=$((chunks > 10 ? 10 : chunks))
            echo "chunks=$chunks" >> $GITHUB_OUTPUT
          else
            echo "should_split=false" >> $GITHUB_OUTPUT
            echo "chunks=1" >> $GITHUB_OUTPUT
          fi
      
      - name: ã‚µã‚¤ã‚ºã‚«ãƒ†ã‚´ãƒªåˆ¤å®š
        id: categorize
        run: |
          total_changes=${{ steps.analyze.outputs.total_changes }}
          
          if [ $total_changes -lt 100 ]; then
            echo "category=small" >> $GITHUB_OUTPUT
          elif [ $total_changes -lt 1000 ]; then
            echo "category=medium" >> $GITHUB_OUTPUT
          elif [ $total_changes -lt 5000 ]; then
            echo "category=large" >> $GITHUB_OUTPUT
          else
            echo "category=extra-large" >> $GITHUB_OUTPUT
          fi

  # é€šå¸¸ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä¸­è¦æ¨¡ä»¥ä¸‹ï¼‰
  standard-review:
    needs: analyze-pr-size
    if: needs.analyze-pr-size.outputs.should_split == 'false'
    uses: NFTTechnology/NFTT-GitHub-Workflows/.github/workflows/reusable-pr-review.yml@main
    with:
      pr_number: ${{ github.event.pull_request.number }}
      repository: ${{ github.repository }}
      review_type: ${{ needs.analyze-pr-size.outputs.size_category == 'small' && 'quick' || 'balanced' }}
    secrets: inherit

  # åˆ†å‰²ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆç”Ÿæˆ
  prepare-chunks:
    needs: analyze-pr-size
    if: needs.analyze-pr-size.outputs.should_split == 'true'
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.create-matrix.outputs.matrix }}
    steps:
      - name: ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—ã¨åˆ†å‰²
        id: create-matrix
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          # å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—
          gh pr view ${{ github.event.pull_request.number }} \
            --repo ${{ github.repository }} \
            --json files \
            --jq '.files[].path' > all_files.txt
          
          # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã§å„ªå…ˆåº¦ä»˜ã‘
          # ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’å„ªå…ˆ
          grep -E '\.(js|ts|jsx|tsx|py|java|go|cs|cpp|c|h|rb|php)$' all_files.txt > source_files.txt || true
          grep -vE '\.(js|ts|jsx|tsx|py|java|go|cs|cpp|c|h|rb|php)$' all_files.txt > other_files.txt || true
          
          # å„ªå…ˆåº¦é †ã«ãƒãƒ¼ã‚¸
          cat source_files.txt other_files.txt > sorted_files.txt
          
          # ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
          chunks=${{ needs.analyze-pr-size.outputs.chunks }}
          chunk_size=$(( ($(wc -l < sorted_files.txt) + chunks - 1) / chunks ))
          
          # ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ç”¨ã®JSONã‚’ç”Ÿæˆ
          matrix='{"chunk":['
          for i in $(seq 0 $((chunks - 1))); do
            start=$((i * chunk_size + 1))
            end=$(((i + 1) * chunk_size))
            
            # ãƒãƒ£ãƒ³ã‚¯ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            sed -n "${start},${end}p" sorted_files.txt > "chunk_${i}.txt"
            
            # base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆæ”¹è¡Œã‚’ä¿æŒï¼‰
            files_b64=$(base64 -w 0 < "chunk_${i}.txt")
            
            if [ $i -gt 0 ]; then
              matrix+=','
            fi
            matrix+="{\"id\":$i,\"files\":\"$files_b64\"}"
          done
          matrix+=']}'
          
          echo "matrix=$matrix" >> $GITHUB_OUTPUT

  # åˆ†å‰²ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œ
  chunked-review:
    needs: [analyze-pr-size, prepare-chunks]
    if: needs.analyze-pr-size.outputs.should_split == 'true'
    strategy:
      matrix: ${{ fromJSON(needs.prepare-chunks.outputs.matrix) }}
      max-parallel: 3  # APIåˆ¶é™ã‚’è€ƒæ…®
    runs-on: ubuntu-latest
    steps:
      - name: ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«å¾©å…ƒ
        id: restore
        run: |
          # base64ãƒ‡ã‚³ãƒ¼ãƒ‰
          echo "${{ matrix.chunk.files }}" | base64 -d > chunk_files.txt
          echo "file_list=$(cat chunk_files.txt | tr '\n' ',' | sed 's/,$//')" >> $GITHUB_OUTPUT
      
      - name: ãƒãƒ£ãƒ³ã‚¯å·®åˆ†å–å¾—
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          # ãƒãƒ£ãƒ³ã‚¯å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å·®åˆ†ã®ã¿å–å¾—
          > chunk_diff.txt
          while IFS= read -r file; do
            echo "diff --git a/$file b/$file" >> chunk_diff.txt
            gh pr diff ${{ github.event.pull_request.number }} \
              --repo ${{ github.repository }} -- "$file" >> chunk_diff.txt || true
          done < chunk_files.txt
      
      - name: ãƒãƒ£ãƒ³ã‚¯ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œ
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          # è»½é‡ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œï¼ˆãƒãƒ£ãƒ³ã‚¯ã”ã¨ï¼‰
          python << 'EOF'
          import os
          import anthropic
          
          client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
          
          with open('chunk_diff.txt', 'r') as f:
              diff_content = f.read()
          
          # ç°¡æ½”ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¦æ±‚
          prompt = f"""
          ä»¥ä¸‹ã®å·®åˆ†ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ï¼ˆãƒãƒ£ãƒ³ã‚¯ {${{ matrix.chunk.id + 1 }}}/{${{ needs.analyze-pr-size.outputs.chunks }}}ï¼‰:
          
          {diff_content[:8000]}  # åˆ¶é™
          
          é‡è¦ãªå•é¡Œã®ã¿ã‚’æœ€å¤§3ã¤æŒ™ã’ã¦ãã ã•ã„ï¼š
          1. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œ
          2. é‡å¤§ãªãƒã‚°
          3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ
          """
          
          response = client.messages.create(
              model="claude-3-5-haiku-20241022",
              max_tokens=500,
              messages=[{"role": "user", "content": prompt}]
          )
          
          with open('review_chunk_${{ matrix.chunk.id }}.md', 'w') as f:
              f.write(f"## ãƒãƒ£ãƒ³ã‚¯ {${{ matrix.chunk.id + 1 }}}/{${{ needs.analyze-pr-size.outputs.chunks }}}\n\n")
              f.write(response.content[0].text)
          EOF
      
      - name: ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        uses: actions/upload-artifact@v4
        with:
          name: review-chunk-${{ matrix.chunk.id }}
          path: review_chunk_${{ matrix.chunk.id }}.md

  # ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœçµ±åˆ
  merge-reviews:
    needs: [analyze-pr-size, chunked-review]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        uses: actions/download-artifact@v4
        with:
          pattern: review-chunk-*
          merge-multiple: true
      
      - name: çµ±åˆãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        run: |
          cat > final_review.md << 'EOF'
          # ğŸ” å¤§è¦æ¨¡PR AI ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ
          
          **PRè¦æ¨¡**: ${{ needs.analyze-pr-size.outputs.size_category }}
          **ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: ${{ needs.analyze-pr-size.outputs.file_count }}
          **ãƒãƒ£ãƒ³ã‚¯æ•°**: ${{ needs.analyze-pr-size.outputs.chunks }}
          
          ---
          
          EOF
          
          # å„ãƒãƒ£ãƒ³ã‚¯ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’çµ±åˆ
          for i in $(seq 0 $((${{ needs.analyze-pr-size.outputs.chunks }} - 1))); do
            if [ -f "review_chunk_${i}.md" ]; then
              cat "review_chunk_${i}.md" >> final_review.md
              echo -e "\n---\n" >> final_review.md
            fi
          done
          
          # ã‚µãƒãƒªãƒ¼è¿½åŠ 
          cat >> final_review.md << 'EOF'
          
          ## ğŸ“Š ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µãƒãƒªãƒ¼
          
          ã“ã®å¤§è¦æ¨¡PRã¯è¤‡æ•°ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã•ã‚Œã¾ã—ãŸã€‚
          å„ãƒãƒ£ãƒ³ã‚¯ã®é‡è¦ãªæŒ‡æ‘˜äº‹é …ã¯ä¸Šè¨˜ã®é€šã‚Šã§ã™ã€‚
          
          ### æ¨å¥¨äº‹é …
          1. å¤§ããªPRã¯å¯èƒ½ãªé™ã‚Šå°ã•ãåˆ†å‰²ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™
          2. æ©Ÿèƒ½ã”ã¨ã«å€‹åˆ¥ã®PRã‚’ä½œæˆã—ã¦ãã ã•ã„
          3. ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®åŠ¹ç‡ã¨å“è³ªãŒå‘ä¸Šã—ã¾ã™
          
          <sub>ğŸ¤– Large PR Handler by [NFTT-GitHub-Workflows](https://github.com/NFTTechnology/NFTT-GitHub-Workflows)</sub>
          EOF
      
      - name: ãƒ¬ãƒ“ãƒ¥ãƒ¼æŠ•ç¨¿
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const review = fs.readFileSync('final_review.md', 'utf8');
            
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: ${{ github.event.pull_request.number }},
              body: review
            });

# ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãƒã‚¤ãƒ³ãƒˆï¼š
# 1. ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’èª¿æ•´ï¼ˆchunk_sizeå¤‰æ•°ï¼‰
# 2. ä¸¦åˆ—å®Ÿè¡Œæ•°ã‚’èª¿æ•´ï¼ˆmax-parallelï¼‰
# 3. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã®å„ªå…ˆé †ä½ã‚’å¤‰æ›´
# 4. ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è©³ç´°åº¦ã‚’èª¿æ•´